"""
Traffic Sign Detection using Laptop Camera
S·ª≠ d·ª•ng YOLO11 ƒë·ªÉ nh·∫≠n di·ªán bi·ªÉn b√°o giao th√¥ng qua webcam laptop
"""

import cv2
import os
from ultralytics import YOLO

# Load YOLO11 model
MODEL_PATH = "src/models/yolo11/weights/best.pt"

def load_model():
    """Load trained YOLO11 model"""
    try:
        # Th·ª≠ load t·ª´ ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi tr∆∞·ªõc
        if os.path.exists(MODEL_PATH):
            model = YOLO(MODEL_PATH)
            print(f"‚úÖ ƒê√£ load model t·ª´: {MODEL_PATH}")
        elif os.path.exists("models/yolo11/weights/best.pt"):
            model = YOLO("models/yolo11/weights/best.pt")
            print("‚úÖ ƒê√£ load model t·ª´: models/yolo11/weights/best.pt")
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y model custom. ƒêang load model pretrained...")
            model = YOLO("yolo11n.pt")
            print("‚úÖ ƒê√£ load model YOLO11n pretrained")
        
        print(f"üìã Classes c·ªßa model: {list(model.names.values())}")
        return model
        
    except Exception as e:
        print(f"‚ùå L·ªói khi load model: {e}")
        return None

def run_camera_detection():
    """Ch·∫°y detection t·ª´ webcam laptop"""
    
    # Load model
    model = load_model()
    if model is None:
        print("‚ùå Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông v√¨ model ch∆∞a ƒë∆∞·ª£c load!")
        return
    
    # M·ªü camera
    print("üì∑ ƒêang m·ªü camera...")
    cap = cv2.VideoCapture(0)  # 0 = camera m·∫∑c ƒë·ªãnh c·ªßa laptop
    
    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü camera! Vui l√≤ng ki·ªÉm tra:")
        print("   - Camera c√≥ ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi ·ª©ng d·ª•ng kh√°c kh√¥ng?")
        print("   - Driver camera ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ch∆∞a?")
        return
    
    # C·∫•u h√¨nh camera
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    print("‚úÖ Camera ƒë√£ s·∫µn s√†ng!")
    print("=" * 50)
    print("üìå H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:")
    print("   - Nh·∫•n 'Q' ƒë·ªÉ tho√°t")
    print("   - Nh·∫•n 'S' ƒë·ªÉ ch·ª•p v√† l∆∞u ·∫£nh hi·ªán t·∫°i")
    print("   - Nh·∫•n 'P' ƒë·ªÉ t·∫°m d·ª´ng/ti·∫øp t·ª•c")
    print("=" * 50)
    
    paused = False
    frame_count = 0
    screenshot_count = 0
    
    # T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh n·∫øu ch∆∞a c√≥
    os.makedirs("captured_images", exist_ok=True)
    
    try:
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    print("‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ camera!")
                    break
                
                frame_count += 1
                
                # Ch·∫°y detection
                results = model(frame, conf=0.5, verbose=False)
                
                # V·∫Ω k·∫øt qu·∫£ l√™n frame
                annotated_frame = results[0].plot()
                
                # Hi·ªÉn th·ªã th√¥ng tin detection
                detections = results[0].boxes
                if detections is not None and len(detections) > 0:
                    for box in detections:
                        class_name = model.names[int(box.cls)]
                        confidence = float(box.conf)
                        print(f"üö¶ Ph√°t hi·ªán: {class_name} - ƒê·ªô tin c·∫≠y: {confidence:.2%}")
                
                # Th√™m th√¥ng tin l√™n m√†n h√¨nh
                cv2.putText(annotated_frame, f"FPS: {cap.get(cv2.CAP_PROP_FPS):.1f}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.putText(annotated_frame, f"Phat hien: {len(detections) if detections is not None else 0}", 
                           (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.putText(annotated_frame, "Nhan Q de thoat | S: Chup | P: Tam dung", 
                           (10, annotated_frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            else:
                # Khi t·∫°m d·ª´ng, hi·ªÉn th·ªã th√¥ng b√°o
                cv2.putText(annotated_frame, "TAM DUNG - Nhan P de tiep tuc", 
                           (annotated_frame.shape[1]//2 - 200, annotated_frame.shape[0]//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # Hi·ªÉn th·ªã frame
            cv2.imshow("Traffic Sign Detection - Camera", annotated_frame)
            
            # X·ª≠ l√Ω ph√≠m b·∫•m
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q') or key == ord('Q'):
                print("üëã ƒêang tho√°t...")
                break
            elif key == ord('s') or key == ord('S'):
                # L∆∞u ·∫£nh
                screenshot_count += 1
                filename = f"captured_images/screenshot_{screenshot_count}.jpg"
                cv2.imwrite(filename, annotated_frame)
                print(f"üì∏ ƒê√£ l∆∞u ·∫£nh: {filename}")
            elif key == ord('p') or key == ord('P'):
                paused = not paused
                if paused:
                    print("‚è∏Ô∏è ƒê√£ t·∫°m d·ª´ng")
                else:
                    print("‚ñ∂Ô∏è Ti·∫øp t·ª•c...")
                    
    except KeyboardInterrupt:
        print("\nüëã ƒê√£ ng·∫Øt b·ªüi ng∆∞·ªùi d√πng!")
        
    finally:
        # Gi·∫£i ph√≥ng camera v√† ƒë√≥ng c·ª≠a s·ªï
        cap.release()
        cv2.destroyAllWindows()
        print("‚úÖ ƒê√£ ƒë√≥ng camera v√† gi·∫£i ph√≥ng t√†i nguy√™n")
        print(f"üìä T·ªïng s·ªë frame ƒë√£ x·ª≠ l√Ω: {frame_count}")

if __name__ == "__main__":
    print("=" * 50)
    print("üö¶ TRAFFIC SIGN DETECTION - CAMERA MODE")
    print("=" * 50)
    run_camera_detection()
